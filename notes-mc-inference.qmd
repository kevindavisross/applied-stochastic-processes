# Inference for Discrete Time Markov Chains {.unnumbered}

{{< include _r_mc_setup.qmd >}}

## Markov's letters: estimating the transition matrix



```{r}
x_obs = c(1, 1, 2, 2, 2, 1, 2, 1, 2, 2, 2, 1, 2, 2, 1, 2, 2, 2, 1, 1, 2)

table(x_obs, lead(x_obs, 1))
```

I couldn't find Markov's actual sequence data, so I created a sequence of states that matches his pair counts.


```{r}
#| warning: false

markov_letter_sequence = read_csv("markov_letter_data.csv")

head(markov_letter_sequence)
```


```{r}
x_obs = markov_letter_sequence$state

table(x_obs, lead(x_obs, 1))
```




Using the `markovchain` package.

```{r}
library(markovchain)
```


```{r}
mc_fit = markovchainFit(data = x_obs, method = "mle")

mc_fit
```

```{r}
createSequenceMatrix(x_obs)

```

These confidence intervals adjust for the correlation

```{r}
multinomialConfidenceIntervals(transitionMatrix =
                                 mc_fit$estimate@transitionMatrix,
                               countsTransitionMatrix = createSequenceMatrix(x_obs))

```

## Markov's letters: long simulated sequence


```{r}

state_names = c("v", "c")

P = rbind(
  c(0.128, 0.872),
  c(0.663, 0.337)
)

pi_0 = c(0.432, 0.568)

```


```{r}
x_current = factor(simulate_single_DTMC_path(c(1, 0), P, 50000))

head(x_current, 10)
```

```{r}
createSequenceMatrix(x_current)

```

```{r}
mc_fit = markovchainFit(data = x_current, method = "mle")

mc_fit
```

The `verifyMarkovProperty` function conduct a goodness of fit hypothesis test to see if a sequence follows a Markov chain.
The null hypothesis is that the sequence is generated from a MC.
If the p-value is small there is evidence that the Markov assumption is NOT reasonable.


```{r}
verifyMarkovProperty(x_current)
```


Now we'll summarize the data ourselves.
First we'll create columns for the current state, next state, and previous state.

```{r}
x = tibble(x_current,
           x_next = lead(x_current, 1),
           x_previous = lag(x_current, 1))

x |> head()
```

Now we'll tabulate the (current state, next state) pairs using both base R and tidyverse.




```{r}
table(x$x_current, x$x_next)
```


```{r}
x_summary = x |>
  group_by(x_current) |>
  count(x_next, name = "count") |>
  filter(!is.na(x_next))

x_summary |> kbl() |> kable_styling()
```



Now we can use the tabulated data to create a bar plot of the conditional distributions of the next state given each current state.
(We'll use ggplot.)





```{r}
x_summary |>
  ggplot(aes(x = x_current,
             y = count,
             fill = x_next)) +
  geom_bar(position = "fill",
           stat = "identity") +
  scale_fill_viridis_d() +
  labs(y = "Conditional probability given current state")
```


The bar plot above shows that it would not be reasonable to consider the data as being generated by an independent sequence.

Now we'll create a plot to assess if the Markov assumption is reasonable.
To do so we need to check if the next state and previous state are conditionally indepdent given the current state.

First we tabulate the (x_previous, x_current, x_next) triples.

Using base R `table`, if you put x_current last it will create tables of (x_previous, x_next) for each value of x_current.

```{r}
table(x$x_previous, x$x_next, x$x_current)
```


```{r}
x_summary_mc = x |>
  group_by(x_current, x_previous) |>
  count(x_next, name = "count") |>
  filter(!is.na(x_next) & !is.na(x_previous))

x_summary_mc |> kbl() |> kable_styling()
```


Now we can use the tabulated data to create a bar plot of the conditional distributions of the next state given each previous state, further conditioned on each current state (using facets).
(We'll use ggplot.)

```{r}
x_summary_mc |>
  ggplot(aes(x = x_previous,
             y = count,
             fill = x_next)) +
  geom_bar(position = "fill",
           stat = "identity") +
  scale_fill_viridis_d() +
  labs(y = "Conditional probability given previous state") +
  facet_wrap(~x_current, labeller = label_both)
```

The plot shows that it is reasonable to consider the sequence as being generated from a Markov chain.





## Weather chain


```{r}
state_names = c("RR", "NR", "RN", "NN")

P = rbind(c(.7, 0, .3, 0),
          c(.5, 0, .5, 0),
          c(0, .4, 0, .6),
          c(0, .2, 0, .8)
)

x_obs = simulate_single_DTMC_path(c(1, 0, 0, 0), P, 100000)

x_current = str_sub(state_names[x_obs], start = 1, end = 1)

x_current |> head()
```


```{r}
x = tibble(x_current,
           x_next = lead(x_current, 1),
           x_previous = lag(x_current, 1))

x |> head()
```
```{r}
x_summary_mc = x |>
  group_by(x_current, x_previous) |>
  count(x_next, name = "count") |>
  filter(!is.na(x_next) & !is.na(x_previous))

x_summary_mc |> kbl() |> kable_styling()
```


```{r}
x_summary_mc |>
  ggplot(aes(x = x_previous,
             y = count,
             fill = x_next)) +
  geom_bar(position = "fill",
           stat = "identity") +
  scale_fill_viridis_d() +
  labs(y = "Conditional probability given previous state") +
  facet_wrap(~x_current, labeller = label_both)
```





From the bar plot we can see that the sequence can NOT be considered to be generated from a first order Markov chain.

Here is a test; note the small p-value (recall that the null hypothesis is a MC model).



```{r}
verifyMarkovProperty(x_current)
```

### Second-order MC


To see if $X_n$ is a second order MC, we'll consider the current state as the pair $Y_n = (X_{n-1}, X_n)$.
The code below creates the y_current pairs, as well as y_previous and y_next.

Note: we actually simulated this sequence by simulating the $Y$ pairs first and then separating into the individual $X$'s, so now we're basically going back to what we started with.
But in practice you would only observe the individual $X$'s.


```{r}
x_and_y = x |>
  filter(!is.na(x_next) & !is.na(x_previous)) |>
  unite("y_current", c("x_previous", "x_current"), remove = FALSE) |>
  mutate(y_next = lead(y_current, 1),
         y_previous = lag(y_current, 1))

x_and_y |> select(x_previous, x_current, y_current, y_previous, y_next) |> head()
  
```


We can assess if $X_n$ is a *second order* MC by assessing if $Y_n$ is a first order MC.


```{r}
y_summary_mc = x_and_y |>
  group_by(y_current, y_previous) |>
  count(y_next, name = "count") |>
  filter(!is.na(y_next) & !is.na(y_previous))

y_summary_mc |> kbl() |> kable_styling()
```

```{r}
y_summary_mc |>
  ggplot(aes(x = y_previous,
             y = count,
             fill = y_next)) +
  geom_bar(position = "fill",
           stat = "identity") +
  scale_fill_viridis_d() +
  labs(y = "Conditional probability given previous state") +
  facet_wrap(~y_current, labeller = label_both)
```
The bar plot shows that it is reasonable to consider $Y$ as being generated from a first order MC, in which case $X$ is a second order MC.
Here is a test.



```{r}
verifyMarkovProperty(x_and_y$y_current)
```
